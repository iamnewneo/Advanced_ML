{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using built-in scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X, y = make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  1],\n",
       "       [ 2, 10]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.92      0.89        13\n",
      "          1       0.91      0.83      0.87        12\n",
      "\n",
      "avg / total       0.88      0.88      0.88        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.909091 f1_score: 0.869565\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, f1_score\n",
    "print(\"Precision score: %f f1_score: %f\" % (precision_score(y_test, pred),\\\n",
    "                                           f1_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area under the roc curve: 0.935897\n",
      "average precision: 0.950575\n",
      "log loss: 0.308483\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss\n",
    "\n",
    "probs = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"area under the roc curve: %f\" % roc_auc_score(y_test, probs))\n",
    "print(\"average precision: %f\" % average_precision_score(y_test, probs))\n",
    "print(\"log loss: %f\" % log_loss(y_test, probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scorers for cross-validation and grid-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['r2', 'accuracy', 'mean_squared_error', 'precision', 'f1_macro', 'f1_samples', 'f1_micro', 'recall_samples', 'precision_weighted', 'f1', 'adjusted_rand_score', 'f1_weighted', 'roc_auc', 'precision_macro', 'average_precision', 'recall_micro', 'mean_absolute_error', 'recall', 'precision_micro', 'recall_weighted', 'precision_samples', 'median_absolute_error', 'recall_macro', 'log_loss'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.scorer import SCORERS\n",
    "print(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82,  0.79,  0.81])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(LogisticRegression(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scoring: [ 0.82  0.79  0.81]\n",
      "F! scoring: [ 0.83  0.79  0.79]\n",
      "AUC scoring: [ 0.94  0.88  0.88]\n",
      "Log loss scoring: [-0.3  -0.58 -0.56]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy scoring: %s\" % cross_val_score(LogisticRegression(), X, y, scoring=\"accuracy\"))\n",
    "print(\"F! scoring: %s\" % cross_val_score(LogisticRegression(), X, y, scoring=\"f1\"))\n",
    "print(\"AUC scoring: %s\" % cross_val_score(LogisticRegression(), X, y, scoring=\"roc_auc\"))\n",
    "print(\"Log loss scoring: %s\" % cross_val_score(LogisticRegression(), X, y, scoring=\"log_loss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([  1.00000e-03,   4.64159e-03,   2.15443e-02,   1.00000e-01,\n",
       "         4.64159e-01,   2.15443e+00,   1.00000e+01,   4.64159e+01,\n",
       "         2.15443e+02,   1.00000e+03])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='log_loss', verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "param_grid = {'C': np.logspace(start=-3, stop=3, num=10)}\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, scoring=\"log_loss\")\n",
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: -0.66258, std: 0.00106, params: {'C': 0.001},\n",
       " mean: -0.58738, std: 0.00455, params: {'C': 0.0046415888336127772},\n",
       " mean: -0.46489, std: 0.01213, params: {'C': 0.021544346900318832},\n",
       " mean: -0.38646, std: 0.03217, params: {'C': 0.10000000000000001},\n",
       " mean: -0.41391, std: 0.08809, params: {'C': 0.46415888336127775},\n",
       " mean: -0.58592, std: 0.16415, params: {'C': 2.154434690031882},\n",
       " mean: -0.94970, std: 0.25540, params: {'C': 10.0},\n",
       " mean: -1.59448, std: 0.45646, params: {'C': 46.415888336127729},\n",
       " mean: -2.39817, std: 0.74119, params: {'C': 215.44346900318823},\n",
       " mean: -3.16412, std: 0.91376, params: {'C': 1000.0}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.10000000000000001}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining your own scoring callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.82  0.79  0.81]\n",
      "[ 0.82  0.79  0.81]\n"
     ]
    }
   ],
   "source": [
    "def my_accuracy_score(est, X, y):\n",
    "    return np.mean(est.predict(X) == y)\n",
    "\n",
    "print(cross_val_score(LogisticRegression(), X, y))\n",
    "print(cross_val_score(LogisticRegression(), X, y, scoring = my_accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83402146985962022"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "fbeta_score(y_test, pred, beta=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.scorer import make_scorer\n",
    "my_fbeta_scorer = make_scorer(fbeta_score, beta=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88  0.77  0.69]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(LogisticRegression(), X, y, scoring = my_fbeta_scorer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
